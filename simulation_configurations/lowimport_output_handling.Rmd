---
title: "lowimport_output_handling"
author: "Daniel T Citron"
date: "10/31/2019"
output: html_document
---

We are going to analyze the outputs from the `lowimport` simulations.

This is for ASTMH.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Load Libraries}
library(data.table)
library(ggplot2)
library(Matrix)
library(here, lib.loc = "/ihme/malaria_modeling/dtcitron/Rlibs")
```

```{r Load population data}
pop.data <- fread(here("SpatialUncertainty/data_clean/aggregated_2015_2018_travel_data.csv"))
areaId.list <- sort(pop.data[year == 2018]$areaId)
pop.dt <- data.table(patch = c(0:(241-1)), areaId = areaId.list)
pop.dt <- merge(pop.dt, pop.data[year == 2018, .(areaId, pop)], by = "areaId")
```


```{r Load PfPR data}
pfpr.data <- fread(here("SpatialUncertainty/data_clean/pfpr_draws.csv"))
pfpr.data <- merge(pfpr.data, pop.data[year == 2018, .(areaId)], by = "areaId", all = FALSE)
```


# Script for Outputting Baseline Bioko Island Simulations

Preliminary analysis of simulation data, with 100 output files.  Each file represents 1 simulation from 6 years of full island simulations, baseline conditions.

# Come up with summary files, means + error bars
```{r Summary Files - means and standard deviations}
# Set ensemble of files to be analyzed
ensemble.file.list <- list.files(path = here("SpatialUncertainty/ASTMH19/lowimport/sim_output"),
                                 pattern = "pfsi_[[:digit:]]+.csv")

# load in the first one
df_curr <- fread(here("SpatialUncertainty/ASTMH19/lowimport/sim_output",ensemble.file.list[1]))
df_curr <- merge(pop.dt, df_curr, by = "patch")
df_curr[, s := (S_resident_home + S_resident_away)/pop, by = c("time" , "patch" , "time")]
df_curr[, i := (I_resident_home + I_resident_away)/pop, by = c("time" , "patch" , "time")]
df_curr[, p := (P_resident_home + P_resident_away)/pop, by = c("time" , "patch" , "time")]
# copy it to create the corresponding matrix:
mat_curr <- as.matrix(df_curr)
# then we use that matrix to create holders to catch data for the means and standard deviations:
mat_mean <- mat_curr
mat_sd <- mat_mean
mat_sd[, 5:ncol(mat_curr)] <- mat_mean[, 5:ncol(mat_curr)]^2
# now we loop over the other files in the list of ensemble outputs
nrun = length(ensemble.file.list)
for (i in 2:nrun){
  df_curr <- fread(here("SpatialUncertainty/ASTMH19/lowimport/sim_output",ensemble.file.list[i]))
  
  df_curr <- merge(pop.dt, df_curr, by = "patch")
  df_curr[, s := (S_resident_home + S_resident_away)/pop, by = c("time" , "patch" , "time")]
  df_curr[, i := (I_resident_home + I_resident_away)/pop, by = c("time" , "patch" , "time")]
  df_curr[, p := (P_resident_home + P_resident_away)/pop, by = c("time" , "patch" , "time")]
  
  mat_curr <- as.matrix(df_curr)
  mat_mean[, 5:ncol(mat_curr)] <- mat_mean[, 5:ncol(mat_curr)] + mat_curr[, 5:ncol(mat_curr)]
  mat_sd[, 5:ncol(mat_curr)] <-  mat_sd[, 5:ncol(mat_curr)] + mat_curr[, 5:ncol(mat_curr)]^2
}
mat_mean <- as.data.table(mat_mean)
mat_sd <- as.data.table(mat_sd)

mat_mean[, 5:ncol(mat_curr)] <- mat_mean[, 5:ncol(mat_curr)]/nrun
mat_sd[, 5:ncol(mat_curr)] <- mat_sd[, 5:ncol(mat_curr)]/nrun - mat_mean[, 5:ncol(mat_curr)]^2
mat_sd[mat_sd < 0] <- 0
mat_sd[, 5:ncol(mat_curr)] <- sqrt(mat_sd[, 5:ncol(mat_curr)])

```

```{r Plotting subset of time series}
h <- melt(mat_mean[areaId %in% c(152, 207, 220,335,502,644,1175,2199,2457)],
     id.vars = c("time", "areaId"), 
     measure.vars = c("s","i","p"),
     value.name = "fraction")
h.sd <- melt(mat_sd[areaId %in% c(152, 207, 220,335,502,644,1175,2199,2457)],
     id.vars = c("time", "areaId"), 
     measure.vars = c("s","i","p"),
     value.name = "fraction.sd")
h <- merge(h, h.sd, by = c("time", "areaId", "variable"))


ggplot(data = h) + 
  geom_errorbar(mapping = aes(x = time, ymin = fraction - fraction.sd, ymax = fraction + fraction.sd, color = variable), alpha = .2) + 
  geom_point(mapping = aes(x = time, y = fraction), color = "black", shape = 16, size = .1) + 
  facet_wrap(~areaId)
```


```{r Save Mean and SD summary files}
fwrite(mat_mean, here("SpatialUncertainty/ASTMH19/lowimport/lowimport_pr_means.csv"))
fwrite(mat_sd, here("SpatialUncertainty/ASTMH19/lowimport/lowimport_pr_sds.csv"))

#mat_mean[areaId == 335 & time == 2000]

```


# Come up with 1 file of 10 example trajectories that we can juxtapose with the summary files


```{r Create a list of 10 example trajectories}
# Set ensemble of files to be analyzed
ensemble.file.list <- list.files(path = here("SpatialUncertainty/ASTMH19/lowimport/sim_output"),
                                 pattern = "pfsi_[[:digit:]]+.csv")

# load in the first one
df <- fread(here("SpatialUncertainty/ASTMH19/lowimport/sim_output",ensemble.file.list[1]))
df <- merge(pop.dt, df, by = "patch")
df[, s := (S_resident_home + S_resident_away)/pop, by = c("time" , "patch" , "time")]
df[, i := (I_resident_home + I_resident_away)/pop, by = c("time" , "patch" , "time")]
df[, p := (P_resident_home + P_resident_away)/pop, by = c("time" , "patch" , "time")]
df[, run := 1]
for (k in 2:10){
  df_curr <- fread(here("SpatialUncertainty/ASTMH19/lowimport/sim_output",ensemble.file.list[k]))
  
  df_curr <- merge(pop.dt, df_curr, by = "patch")
  df_curr[, s := (S_resident_home + S_resident_away)/pop, by = c("time" , "patch" , "time")]
  df_curr[, i := (I_resident_home + I_resident_away)/pop, by = c("time" , "patch" , "time")]
  df_curr[, p := (P_resident_home + P_resident_away)/pop, by = c("time" , "patch" , "time")]
  df_curr[, run:= k]
  
  df <- rbind(df, df_curr)
}

```

```{r Plot examples}
h <- melt(df[areaId %in% c(152, 207, 220,335,502,644,1175,2199,2457)],
     id.vars = c("time", "areaId", "run"), 
     measure.vars = c("s","i","p"),
     value.name = "fraction")

ggplot(data = h) + 
  #geom_errorbar(mapping = aes(x = time, ymin = fraction - fraction.sd, ymax = fraction + fraction.sd, color = variable), alpha = .2) + 
  geom_point(mapping = aes(x = time, y = fraction, color = variable), size = .01, shape = 16) + 
  facet_wrap(~areaId)
```



```{r Save Summary Files}
fwrite(df, here("SpatialUncertainty/ASTMH19/lowimport/lowimport_pr_subsample.csv"))
```

The next step is to compare the travel fraction time series to the baseline time series

```{r}
base.pr <- fread(here("SpatialUncertainty/ASTMH19/baseline/baseline_pr_means.csv"))

li.pr <- fread(here("SpatialUncertainty/ASTMH19/lowimport/lowimport_pr_means.csv"))

travel.fraction <- merge(li.pr[,.(areaId, time, li.i = i)], base.pr[,.(areaId, time, base.i = i)], by = c("areaId", "time"))

travel.fraction[, li := li.i/base.i, by = c("areaId", "time")]

travel.fraction[time == 2000]
```

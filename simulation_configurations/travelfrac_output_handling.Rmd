---
title: "travelfrac_output_handling"
author: "Daniel T Citron"
date: "10/31/2019"
output: html_document
---


We are going to analyze the outputs from the `travelfrac` simulations.

This is for ASTMH.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Load Libraries}
library(data.table)
library(ggplot2)
library(Matrix)
library(here, lib.loc = "/ihme/malaria_modeling/dtcitron/Rlibs")
```

```{r Load population data}
pop.data <- fread(here("SpatialUncertainty/data_clean/aggregated_2015_2018_travel_data.csv"))
areaId.list <- sort(pop.data[year == 2018]$areaId)
pop.dt <- data.table(patch = c(0:(241-1)), areaId = areaId.list)
pop.dt <- merge(pop.dt, pop.data[year == 2018, .(areaId, pop)], by = "areaId")
```


```{r Load PfPR data}
pfpr.data <- fread(here("SpatialUncertainty/data_clean/pfpr_draws.csv"))
pfpr.data <- merge(pfpr.data, pop.data[year == 2018, .(areaId)], by = "areaId", all = FALSE)
```


# Script for Outputting Baseline Bioko Island Simulations

Preliminary analysis of simulation data, with 100 output files.  Each file represents 1 simulation from 6 years of full island simulations, baseline conditions.

# Come up with summary files, means + error bars
```{r Summary Files - means and standard deviations}
# Set ensemble of files to be analyzed
ensemble.file.list <- list.files(path = here("SpatialUncertainty/ASTMH19/travelfrac/sim_output"),
                                 pattern = "pfsi_[[:digit:]]+.csv")

# load in the first one
df_curr <- fread(here("SpatialUncertainty/ASTMH19/travelfrac/sim_output",ensemble.file.list[1]))
df_curr <- merge(pop.dt, df_curr, by = "patch")
df_curr[, s := (S_resident_home + S_resident_away)/pop, by = c("time" , "patch" , "time")]
df_curr[, i := (I_resident_home + I_resident_away)/pop, by = c("time" , "patch" , "time")]
df_curr[, p := (P_resident_home + P_resident_away)/pop, by = c("time" , "patch" , "time")]
# copy it to create the corresponding matrix:
mat_curr <- as.matrix(df_curr)
# then we use that matrix to create holders to catch data for the means and standard deviations:
mat_mean <- mat_curr
mat_sd <- mat_mean
mat_sd[, 5:ncol(mat_curr)] <- mat_mean[, 5:ncol(mat_curr)]^2
# now we loop over the other files in the list of ensemble outputs
nrun = length(ensemble.file.list)
for (i in 2:nrun){
  df_curr <- fread(here("SpatialUncertainty/ASTMH19/travelfrac/sim_output",ensemble.file.list[i]))
  
  df_curr <- merge(pop.dt, df_curr, by = "patch")
  df_curr[, s := (S_resident_home + S_resident_away)/pop, by = c("time" , "patch" , "time")]
  df_curr[, i := (I_resident_home + I_resident_away)/pop, by = c("time" , "patch" , "time")]
  df_curr[, p := (P_resident_home + P_resident_away)/pop, by = c("time" , "patch" , "time")]
  
  mat_curr <- as.matrix(df_curr)
  mat_mean[, 5:ncol(mat_curr)] <- mat_mean[, 5:ncol(mat_curr)] + mat_curr[, 5:ncol(mat_curr)]
  mat_sd[, 5:ncol(mat_curr)] <-  mat_sd[, 5:ncol(mat_curr)] + mat_curr[, 5:ncol(mat_curr)]^2
}
mat_mean <- as.data.table(mat_mean)
mat_sd <- as.data.table(mat_sd)

mat_mean[, 5:ncol(mat_curr)] <- mat_mean[, 5:ncol(mat_curr)]/nrun
mat_sd[, 5:ncol(mat_curr)] <- mat_sd[, 5:ncol(mat_curr)]/nrun - mat_mean[, 5:ncol(mat_curr)]^2
mat_sd[mat_sd < 0] <- 0
mat_sd[, 5:ncol(mat_curr)] <- sqrt(mat_sd[, 5:ncol(mat_curr)])

```

```{r Plotting subset of time series}
h <- melt(mat_mean[areaId %in% c(152, 207, 220,335,502,644,1175,2199,2457)],
     id.vars = c("time", "areaId"), 
     measure.vars = c("s","i","p"),
     value.name = "fraction")
h.sd <- melt(mat_sd[areaId %in% c(152, 207, 220,335,502,644,1175,2199,2457)],
     id.vars = c("time", "areaId"), 
     measure.vars = c("s","i","p"),
     value.name = "fraction.sd")
h <- merge(h, h.sd, by = c("time", "areaId", "variable"))


ggplot(data = h) + 
  geom_errorbar(mapping = aes(x = time, ymin = fraction - fraction.sd, ymax = fraction + fraction.sd, color = variable), alpha = .2) + 
  geom_point(mapping = aes(x = time, y = fraction), color = "black", shape = 16, size = .1) + 
  facet_wrap(~areaId)
```


```{r Save Mean and SD summary files}
fwrite(mat_mean, here("SpatialUncertainty/ASTMH19/travelfrac/travelfrac_pr_means.csv"))
fwrite(mat_sd, here("SpatialUncertainty/ASTMH19/travelfrac/travelfrac_pr_sds.csv"))

#mat_mean[areaId == 335 & time == 2000]

```


# Come up with 1 file of 10 example trajectories that we can juxtapose with the summary files


```{r Create a list of 10 example trajectories}
# Set ensemble of files to be analyzed
ensemble.file.list <- list.files(path = here("SpatialUncertainty/ASTMH19/travelfrac/sim_output"),
                                 pattern = "pfsi_[[:digit:]]+.csv")

# load in the first one
df <- fread(here("SpatialUncertainty/ASTMH19/travelfrac/sim_output",ensemble.file.list[1]))
df <- merge(pop.dt, df, by = "patch")
df[, s := (S_resident_home + S_resident_away)/pop, by = c("time" , "patch" , "time")]
df[, i := (I_resident_home + I_resident_away)/pop, by = c("time" , "patch" , "time")]
df[, p := (P_resident_home + P_resident_away)/pop, by = c("time" , "patch" , "time")]
df[, run := 1]
for (k in 2:10){
  df_curr <- fread(here("SpatialUncertainty/ASTMH19/travelfrac/sim_output",ensemble.file.list[k]))
  
  df_curr <- merge(pop.dt, df_curr, by = "patch")
  df_curr[, s := (S_resident_home + S_resident_away)/pop, by = c("time" , "patch" , "time")]
  df_curr[, i := (I_resident_home + I_resident_away)/pop, by = c("time" , "patch" , "time")]
  df_curr[, p := (P_resident_home + P_resident_away)/pop, by = c("time" , "patch" , "time")]
  df_curr[, run:= k]
  
  df <- rbind(df, df_curr)
}

```

```{r Plot examples}
h <- melt(df[areaId %in% c(152, 207, 220,335,502,644,1175,2199,2457)],
     id.vars = c("time", "areaId", "run"), 
     measure.vars = c("s","i","p"),
     value.name = "fraction")

ggplot(data = h) + 
  #geom_errorbar(mapping = aes(x = time, ymin = fraction - fraction.sd, ymax = fraction + fraction.sd, color = variable), alpha = .2) + 
  geom_point(mapping = aes(x = time, y = fraction, color = variable), size = .01, shape = 16) + 
  facet_wrap(~areaId)
```



```{r Save Summary Files}
fwrite(df, here("SpatialUncertainty/ASTMH19/travelfrac/travelfrac_pr_subsample.csv"))
```

The next step is to compare the travel fraction time series to the baseline time series

```{r}
base.pr <- fread(here("SpatialUncertainty/ASTMH19/baseline/baseline_pr_means.csv"))

tf.pr <- fread(here("SpatialUncertainty/ASTMH19/travelfrac/travelfrac_pr_means.csv"))

travel.fraction <- merge(tf.pr[,.(areaId, time, tf.i = i)], base.pr[,.(areaId, time, base.i = i)], by = c("areaId", "time"))

travel.fraction[, tf := tf.i/base.i, by = c("areaId", "time")]


```

In this next part, we will show how and why it is that the estimates of travel fraction appear to have halved everywhere.
We will compare our predicted and simulated travel fractions, and show how that changes when we change the off-island FOI.

```{r}
# Low-h
pfpr.input <- c(rep(0, 241), 0.43) #pfpr.input <- c(pop.data$pfpr, 0.43) # TF: don't need this
odds.vector <- r/(1-rho)*pfpr.input/(1-(1+rho*r/eta/(1-rho))*pfpr.input)
h.FOI <- MASS::ginv(TaR.matrix) %*% odds.vector
h.FOI[which(h.FOI < 0)] <- 0
pr.low <- TaR.matrix %*% h.FOI/(r + TaR.matrix %*% h.FOI)

#High-h
pfpr.input.high <- c(rep(0, 241), 0.6) #pfpr.input <- c(pop.data$pfpr, 0.43) # TF: don't need this
odds.vector.high <- r/(1-rho)*pfpr.input.high/(1-(1+rho*r/eta/(1-rho))*pfpr.input.high)
h.FOI.high <- MASS::ginv(TaR.matrix) %*% odds.vector.high
h.FOI.high[which(h.FOI.high < 0)] <- 0
pr.high <- TaR.matrix %*% h.FOI.high/(r + TaR.matrix %*% h.FOI.high)

# compare these with the travel.fraction
q <- pfpr.data[,.(areaId, pfpr = draw.mean)]
q$pr.low <- pr.low[1:241]
q$pr.high <- pr.high[1:241]
q$tf.low <- q$pr.low/q$pfpr
q$tf.high <- q$pr.high/q$pfp

travel.fraction <- merge(travel.fraction, q, by = "areaId")

fwrite(travel.fraction[time == 2000], here("SpatialUncertainty/ASTMH19/travelfrac/travelfrac_output.csv"))

```

